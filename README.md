# ğŸ“ˆ Pipeline de AnÃ¡lise B3

Pipeline de dados completo para anÃ¡lise de aÃ§Ãµes da B3 (Bolsa de Valores Brasileira), integrando coleta automatizada de cotaÃ§Ãµes via Yahoo Finance, armazenamento em banco NoSQL, orquestraÃ§Ã£o de pipelines de ETL e visualizaÃ§Ã£o interativa com dashboard e alertas em tempo real. Este projeto demonstra uma arquitetura end-to-end envolvendo **Flask**, **yfinance**, **Apache Cassandra**, **Apache Airflow** e **Grafana**.

---

## ğŸ§© DescriÃ§Ã£o do Projeto

O Pipeline de AnÃ¡lise B3 realiza a coleta periÃ³dica de dados de cotaÃ§Ãµes de ativos listados na B3 e os disponibiliza em um painel analÃ­tico. Os principais componentes sÃ£o:

- **API Flask + yfinance** â€“ ServiÃ§o Flask que utiliza a biblioteca `yfinance` para obter cotaÃ§Ãµes do Yahoo Finance. Fornece endpoints REST que permitem recuperar dados histÃ³ricos de ativos em formato JSON.
- **Banco de dados Apache Cassandra** â€“ Banco NoSQL distribuÃ­do usado para armazenar as cotaÃ§Ãµes coletadas. Foi escolhido pela eficiÃªncia em gravaÃ§Ãµes frequentes e consultas por chave primÃ¡ria.
- **OrquestraÃ§Ã£o Apache Airflow** â€“ Scheduler responsÃ¡vel por gerenciar duas DAGs de ETL: uma para coleta periÃ³dica de dados e outra para limpeza diÃ¡ria de dados antigos no banco.
- **Dashboard Grafana (Plugin JSON API)** â€“ Interface de visualizaÃ§Ã£o dos dados de mercado, construÃ­da no Grafana utilizando o plugin JSON API para consumir os dados diretamente da API Flask.

---

## âœ… Requisitos

- **Docker** (Docker Engine 20.x ou superior)
- **Docker Compose** (v2 ou integrado)
- **Windows** (para uso com `.bat`)

âš ï¸ Portas utilizadas:
- Cassandra: `9042`
- API Flask: `5000`
- Airflow: `8082`
- Grafana: `3000`

---

## ğŸš€ Como Executar

Clone o repositÃ³rio:

```bash
git clone https://github.com/usuario/pipeline-financeiro-b3.git
cd pipeline-financeiro-b3
```

Execute o script de inicializaÃ§Ã£o:

```bash
start_projeto_financas.bat
```

O script irÃ¡:
- Subir todos os containers Docker
- Aguardar a inicializaÃ§Ã£o dos serviÃ§os
- Instalar dependÃªncias no Airflow
- Reiniciar o Airflow para carregar as DAGs
- Abrir as interfaces no navegador

### Interfaces:
- [Airflow](http://localhost:8082)
- [API de CotaÃ§Ãµes (Flask)](http://localhost:5000/cotacoes)
- [Grafana](http://localhost:3000)

Para encerrar:

```bash
end_projeto.bat
```

---

## ğŸ§  Funcionamento do Pipeline

1. **Carga Inicial**: A API Flask cria a estrutura no Cassandra e carrega 60 dias de histÃ³rico por ativo usando `yfinance`.
2. **Coleta com Airflow**: DAG `coleta_ativos_direto_cassandra` roda a cada 15 minutos, inserindo novas cotaÃ§Ãµes no banco.
3. **Limpeza DiÃ¡ria**: DAG `limpeza_diaria_dag` remove registros antigos mantendo uma janela deslizante no Cassandra.
4. **Consulta via API Flask**:
    - `/ativos`: lista de tickers
    - `/cotacoes`: todas as cotaÃ§Ãµes
    - `/cotacoes/<ticker>?campo=close`: sÃ©rie temporal formatada para o Grafana

5. **VisualizaÃ§Ã£o com Grafana**:
    - Fonte de dados JSON API apontando para a API Flask
    - Dashboard provisionado com grÃ¡ficos:
        - Abertura, MÃ¡xima, MÃ­nima, Fechamento, Volume
    - Alertas:
        - Queda > 5%
        - Volume > 10 milhÃµes

---

## ğŸ§ª Trechos de CÃ³digo Relevantes

### ğŸ”¹ Endpoint Flask
```python
@app.route("/cotacoes/<ticker>")
def listar_por_ativo(ticker):
    campo = request.args.get("campo", "close")
    ...
    return jsonify([{"datapoints": dados}])
```

### ğŸ”¹ DAG Airflow
```python
with DAG(
    dag_id='coleta_ativos_direto_cassandra',
    schedule_interval='*/15 * * * *',
) as dag:
    tarefa_coleta = PythonOperator(
        task_id='coletar_ativos',
        python_callable=coletar_ativos
    )
```

### ğŸ”¹ Script .BAT
```bat
docker-compose up -d --build
timeout /t 90 >nul
docker exec -it airflow-web pip install --user yfinance pandas cassandra-driver
docker restart airflow-web
docker restart airflow-scheduler
start http://localhost:8082
start http://localhost:5000/cotacoes
start http://localhost:3000
docker logs api-ibov --follow
```

---

## ğŸ“¦ Provisionamento Grafana

- `provisioning/datasources/datasource.yaml`: define a fonte JSON API (uid: `json-api`)
- `provisioning/dashboards/dashboard.yaml`: carrega o dashboard `dashboard.json`
- Os painÃ©is e alertas sÃ£o automaticamente carregados ao subir o container Grafana

---

## ğŸ”” Alertas no Dashboard

- **Alerta de Queda**: dispara se o preÃ§o de fechamento cair >5% na Ãºltima hora
- **Alerta de Volume Alto**: dispara se o volume ultrapassar 10 milhÃµes

---

## ğŸ“ Estrutura do Projeto

```plaintext
project-root/
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api_ibov.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ provisioning/
â”‚   â”œâ”€â”€ datasources/
â”‚   â””â”€â”€ dashboards/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ start_projeto_financas.bat
â””â”€â”€ end_projeto.bat
```

---

## ğŸ¥ DemonstraÃ§Ã£o

- ğŸ“½ï¸ **VÃ­deo do Projeto**: 
- ğŸ–¼ï¸ **Screenshot do Dashboard**: ![Dashboard Grafana](https://i.imgur.com/xdc5A7U.png)

---

## ğŸ§¼ ObservaÃ§Ãµes Finais

- Evite reexecutar DAGs manualmente fora do horÃ¡rio de pregÃ£o
- Alertas sÃ£o configurados apenas para fins de demonstraÃ§Ã£o
- O `.bat` simplifica o setup para ambiente local e acadÃªmico
- Para produÃ§Ã£o, recomenda-se gestÃ£o de credenciais, seguranÃ§a e volumes externos

---

**Desenvolvido por Guilherme de Oliveira | Mestrando em ComputaÃ§Ã£o Aplicada**
